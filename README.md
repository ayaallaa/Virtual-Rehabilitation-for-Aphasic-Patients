# Virtual-Rehabilitation-for-Aphasic-Arabic-Speaking-Patients

Objective:

Individuals with aphasia often experience significant problems in their daily lives and social participation. 
Technologies that address speech and language disorders deficit in merging between therapistâ€™s major role and reinforcing the training between sessions at home. 
It also lacks the Arabic language attention; however, current systems are typically expensive and lack amusement. 
Moreover, cumulative feedback for both patient and therapist incapacitates the whole home rehabilitation process. 
This project sought to address these issues by developing an interactive rehabilitation-based system for people with aphasia. 


Methods:

A virtual reality (VR) environment is created providing real-life situations with task specific training of comprehension 
in addition to a virtual speech-language pathologist (SLP) representing lip motions for correct pronunciation of target words. 
A speech recognition convolutional neural networks (CNN) algorithm based on signal processing is created and trained on ten isolated Arabic words. 
We tempted log-spectrograms and Mel-frequency cepstral coefficients (MFCC) as feature extractors for the CNN model 
which is then integrated for accurate evaluation of input speech from the aphasic patient providing a real-time feedback 
resulting in measuring speech improvement and sends it to the SLP through the network via a website platform. 


Results:

Our speech recognition assessment algorithm results in a recognition accuracy of 95.2 % using Log-Spectrograms feature extraction method 
and 92.6 % using MFCC. 


Significance & Conclusion:

We hypothesize that this interactive VR therapy combined with speech function training will result in faster word retrieval 
and improve language ability of patients with aphasia and that our outcomes contribute to the development of a home-based language and speech therapy.
